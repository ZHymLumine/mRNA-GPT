import argparse
import os
import pandas as pd
import numpy as np
import torch
from rna2sta import RNAStabilityPredictor

def main():
    parser = argparse.ArgumentParser(description="ç­›é€‰çœŸå®ç¨³å®šæ€§å€¼å’Œé¢„æµ‹ç¨³å®šæ€§å€¼éƒ½é«˜äº0.5çš„mRNAåºåˆ—")
    parser.add_argument("--csv", default="mRNA_Stability.csv", help="è¾“å…¥CSVæ–‡ä»¶è·¯å¾„ï¼Œéœ€åŒ…å«åˆ—: Sequence, Value")
    parser.add_argument("--model", default="best_transformer_model.pth", help="è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„")
    parser.add_argument("--threshold", type=float, default=0.5, help="ç¨³å®šæ€§é˜ˆå€¼ï¼Œé»˜è®¤0.5")
    parser.add_argument("--batch_size", type=int, default=16, help="é¢„æµ‹æ‰¹é‡å¤§å°ï¼Œé»˜è®¤16ï¼ˆé¿å…å†…å­˜æº¢å‡ºï¼‰")
    parser.add_argument("--out", default="high_stability_sequences.csv", help="è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--pred_csv", default="pred_vs_actual_stability_transformer.csv", help="é¢„æµ‹ç»“æœCSVæ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.csv):
        raise FileNotFoundError(f"è¾“å…¥CSVæ–‡ä»¶ä¸å­˜åœ¨: {args.csv}")
    
    print(f"ğŸ“Š æ­£åœ¨è¯»å–æ•°æ®æ–‡ä»¶: {args.csv}")
    df_original = pd.read_csv(args.csv)
    
    if "Sequence" not in df_original.columns or "Value" not in df_original.columns:
        raise ValueError("è¾“å…¥CSVå¿…é¡»åŒ…å«åˆ—: Sequence å’Œ Value")
    
    print(f"ğŸ“ˆ æ•°æ®é›†åŒ…å« {len(df_original)} ä¸ªåºåˆ—")
    print(f"ğŸ“ ç¨³å®šæ€§å€¼èŒƒå›´: {df_original['Value'].min():.3f} åˆ° {df_original['Value'].max():.3f}")
    print(f"ğŸ“Š å¹³å‡ç¨³å®šæ€§å€¼: {df_original['Value'].mean():.3f}")
    
    # æ–¹æ³•1: å¦‚æœé¢„æµ‹ç»“æœæ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨
    if os.path.exists(args.pred_csv):
        print(f"ğŸ” æ‰¾åˆ°é¢„æµ‹ç»“æœæ–‡ä»¶: {args.pred_csv}")
        df_pred = pd.read_csv(args.pred_csv)
        
        # åˆå¹¶åŸå§‹æ•°æ®å’Œé¢„æµ‹ç»“æœ
        if len(df_pred) != len(df_original):
            print(f"âš ï¸  è­¦å‘Š: é¢„æµ‹ç»“æœæ•°é‡ ({len(df_pred)}) ä¸åŸå§‹æ•°æ®æ•°é‡ ({len(df_original)}) ä¸åŒ¹é…")
            print("å°†é‡æ–°è¿›è¡Œé¢„æµ‹...")
            use_existing_predictions = False
        else:
            df_combined = df_original.copy()
            df_combined["Predicted"] = df_pred["Predicted"].values
            use_existing_predictions = True
    else:
        use_existing_predictions = False
    
    # æ–¹æ³•2: å¦‚æœæ²¡æœ‰é¢„æµ‹ç»“æœæ–‡ä»¶æˆ–æ•°é‡ä¸åŒ¹é…ï¼Œé‡æ–°é¢„æµ‹
    if not use_existing_predictions:
        if not os.path.exists(args.model):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        
        print(f"ğŸ¤– æ­£åœ¨åŠ è½½æ¨¡å‹: {args.model}")
        predictor = RNAStabilityPredictor(model_path=args.model)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°å¤„ç†æ•°æ®ä»¥è·å–é¢„å¤„ç†å‚æ•°
        try:
            # å°è¯•åŠ è½½æ¨¡å‹ï¼Œå¦‚æœå¤±è´¥åˆ™éœ€è¦é‡æ–°é¢„å¤„ç†æ•°æ®
            checkpoint = torch.load(args.model, map_location='cpu')
            if not isinstance(checkpoint, dict) or 'scaler' not in checkpoint:
                print("âš ï¸  æ£€æµ‹åˆ°æ—§æ ¼å¼æ¨¡å‹æ–‡ä»¶ï¼Œéœ€è¦é¢„å¤„ç†å°‘é‡æ•°æ®æ¥è·å–ç¼–ç å™¨å‚æ•°...")
                # åªé¢„å¤„ç†å‰1000è¡Œæ•°æ®æ¥è·å–encoderå’Œscalerï¼ˆèŠ‚çœæ—¶é—´ï¼‰
                df_sample = df_original.head(1000)
                temp_X, temp_y, temp_splits = predictor.preprocess_data_from_df(df_sample)
                print("âœ… é¢„å¤„ç†å‚æ•°å·²ä»æ ·æœ¬æ•°æ®ç”Ÿæˆ")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ“ å»ºè®®é‡æ–°è®­ç»ƒæ¨¡å‹æˆ–æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„")
            return
        
        print(f"ğŸ”® æ­£åœ¨è¿›è¡Œé¢„æµ‹ï¼ˆæ‰¹é‡å¤§å°: {args.batch_size}ï¼‰...")
        print(f"ğŸ’¾ GPUå†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆé¢„æµ‹å‰ï¼‰: {torch.cuda.memory_allocated()/1024**3:.2f} GB" if torch.cuda.is_available() else "ä½¿ç”¨CPUè¿›è¡Œé¢„æµ‹")
        
        sequences = df_original["Sequence"].astype(str).tolist()
        predictions = predictor.predict(sequences, batch_size=args.batch_size)
        
        # æ¸…ç†å†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print(f"ğŸ’¾ GPUå†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆé¢„æµ‹åï¼‰: {torch.cuda.memory_allocated()/1024**3:.2f} GB")
        
        df_combined = df_original.copy()
        df_combined["Predicted"] = predictions
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        pred_result = pd.DataFrame({
            "Actual": df_combined["Value"],
            "Predicted": predictions
        })
        pred_result.to_csv("predictions_for_filtering.csv", index=False)
        print(f"ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: predictions_for_filtering.csv")
    
    # ç­›é€‰é«˜ç¨³å®šæ€§åºåˆ—
    print(f"ğŸ¯ ç­›é€‰é˜ˆå€¼: {args.threshold}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    high_actual = df_combined["Value"] > args.threshold
    high_predicted = df_combined["Predicted"] > args.threshold
    both_high = high_actual & high_predicted
    
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   çœŸå®å€¼ > {args.threshold}: {high_actual.sum()} ä¸ªåºåˆ— ({high_actual.mean()*100:.1f}%)")
    print(f"   é¢„æµ‹å€¼ > {args.threshold}: {high_predicted.sum()} ä¸ªåºåˆ— ({high_predicted.mean()*100:.1f}%)")
    print(f"   ä¸¤è€…éƒ½ > {args.threshold}: {both_high.sum()} ä¸ªåºåˆ— ({both_high.mean()*100:.1f}%)")
    
    # ç­›é€‰ç»“æœ
    df_filtered = df_combined[both_high].copy()
    
    if len(df_filtered) == 0:
        print(f"âš ï¸  æ²¡æœ‰æ‰¾åˆ°åŒæ—¶æ»¡è¶³æ¡ä»¶çš„åºåˆ—ï¼ˆçœŸå®å€¼å’Œé¢„æµ‹å€¼éƒ½ > {args.threshold}ï¼‰")
        print("ğŸ”§ å»ºè®®é™ä½é˜ˆå€¼æˆ–æ£€æŸ¥æ¨¡å‹æ€§èƒ½")
        return
    
    # æ·»åŠ é¢å¤–ä¿¡æ¯
    df_filtered["Stability_Difference"] = df_filtered["Predicted"] - df_filtered["Value"]
    df_filtered["Average_Stability"] = (df_filtered["Predicted"] + df_filtered["Value"]) / 2
    
    # æŒ‰å¹³å‡ç¨³å®šæ€§æ’åº
    df_filtered = df_filtered.sort_values("Average_Stability", ascending=False)
    
    # ä¿å­˜ç»“æœ
    df_filtered.to_csv(args.out, index=False)
    
    print(f"âœ… ç­›é€‰å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {args.out}")
    print(f"ğŸ“Š ç­›é€‰å‡º {len(df_filtered)} ä¸ªé«˜ç¨³å®šæ€§åºåˆ—")
    print(f"ğŸ“ˆ ç­›é€‰åºåˆ—çš„ç¨³å®šæ€§èŒƒå›´:")
    print(f"   çœŸå®å€¼: {df_filtered['Value'].min():.3f} - {df_filtered['Value'].max():.3f}")
    print(f"   é¢„æµ‹å€¼: {df_filtered['Predicted'].min():.3f} - {df_filtered['Predicted'].max():.3f}")
    print(f"   å¹³å‡ç¨³å®šæ€§: {df_filtered['Average_Stability'].min():.3f} - {df_filtered['Average_Stability'].max():.3f}")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªåºåˆ—çš„ä¿¡æ¯
    if len(df_filtered) > 0:
        print(f"\nğŸ” ç¨³å®šæ€§æœ€é«˜çš„5ä¸ªåºåˆ—:")
        top_sequences = df_filtered.head(5)
        for i, (idx, row) in enumerate(top_sequences.iterrows(), 1):
            seq_preview = row['Sequence'][:50] + "..." if len(row['Sequence']) > 50 else row['Sequence']
            print(f"   {i}. çœŸå®å€¼: {row['Value']:.3f}, é¢„æµ‹å€¼: {row['Predicted']:.3f}, å¹³å‡: {row['Average_Stability']:.3f}")
            print(f"      åºåˆ—: {seq_preview}")

if __name__ == "__main__":
    main()